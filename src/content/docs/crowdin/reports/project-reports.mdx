---
title: Project Reports
description: View your project status and various localization reports
slug: project-reports
sidebar:
  order: 0
---

import { Image } from 'astro:assets';
import Include from '~/components/Include.astro';
import { Steps, Aside, LinkCard } from '@astrojs/starlight/components';
import { Icon } from 'astro-icon/components';
import projectStatus from '!/crowdin/reports/reports_project_status.png';
import dashboard from '!/crowdin/reports/reports_dashboard.png';
import costEstimateGenerating from '!/crowdin/reports/reports_cost_estimate_generating.png';
import addTmMatchType from '!/crowdin/reports/reports_cost_estimate_add_tm_match_type.png';
import addCustomRates from '!/crowdin/reports/reports_add_custom_rates.png';
import translationCostGenerating from '!/crowdin/reports/reports_translation_cost_generating.png';
import addMtMatchType from '!/crowdin/reports/reports_add_mt_match_type.png';
import addCustomRatesTranslationCost from '!/crowdin/reports/reports_translation_cost_add_custom_rates.png';
import costEstimateGenerated from '!/crowdin/reports/reports_cost_estimate_generated.png';
import translationCostGenerated from '!/crowdin/reports/reports_translation_cost_generated.png';
import preTranslationAccuracyGenerated from '!/crowdin/reports/reports_pre_translation_accuracy_generated.png';
import translatorAccuracyGenerated from '!/crowdin/reports/reports_translator_accuracy_generated.png';
import topMembers from '!/crowdin/reports/reports_top_members.png';
import archiveViewing from '!/crowdin/reports/reports_archive_viewing.png';

To view your project status, assess the effectiveness of pre-translation methods, estimate and count the translation cost, keep track of the most active members, and view historical data of previously generated reports, open your project and go to the **Reports** tab.
<Image src={projectStatus} alt="Project Status" />

## Project Status

Use this report to track the progress in your project and review key activities based on time periods.

<Aside>
  The Project Status report shows information about all the translations made in the project (including duplicate translations made by the same translator, removed translations, etc.).
</Aside>

You can find key statistics regarding your project at the top of the page:

- *Size* &ndash; the total amount of text in the project.
- *Translatable* &ndash; the amount of text visible to translators.
- *Source language* &ndash; the source language of your project.
- *Target languages* &ndash; number of the target languages in your project.
- *Members* &ndash; number of project participants.
- *Managers* &ndash; number of project managers.
- *Hidden* &ndash; the amount of text hidden from translators. The owner and managers can see them.
- *Duplicates* &ndash; the amount of text in strings repeating within the project.

### Reviewing Activities

You can review activities based on five time periods: Day, Week, Month, Year, and Custom Range. For a report unit, you can choose from the following types: words, strings, characters, and characters with spaces. Comparisons shown in percentage are counted by comparing the chosen period of time to the same previous period of time (e.g., if you select a month, the current month will be compared to the previous one).

<Image src={dashboard} alt="Reports Dashboard" />

Also, the Project Status report provides a comprehensive visual analysis of the project's translation progress using the following graphs: Translation Activity, Proofreading Activity, Source Strings Activity, and Translation Savings.

The graphs are generated based on the text unit type selected for the Project Status report.

* **Translation activity:** displays the volume of translated units (words, strings, characters) over time. It displays multiple lines simultaneously - units translated by human translators, units translated by Translation Memory (TM), units translated by Machine Translation (MT), and units translated by AI. By hovering over the data points, you can view daily or monthly totals for each category. To view the text translated for each language separately, click the expand arrow next to the graph name.

* **Proofreading activity:** displays the approval and voting activities within your project. It shows two lines - approved units and vote quantities, allowing you to see how review activity is trending over time. By hovering over the data points, you can view the daily or monthly number of approved texts and votes. To view the text approved and votes made for each language separately, click the expand arrow next to the graph name.

* **Source strings activity:** displays the number of units added, deleted, or updated over time. By hovering over the bars, you can see the specific changes that occurred each day or month.

* **Translation savings:** displays the savings achieved through use of Translation Memory (TM), Machine Translation (MT), and AI-assisted translation. You can switch between viewing savings as a percentage of translated units or in currency. The graph provides a breakdown of savings by translation method, which can be viewed for all target languages or for specific languages. Hovering over the bars provides detailed information on savings per method on a daily or monthly basis.

Each graph allows you to focus on specific data by hovering over elements for more detailed information or by adjusting display settings to highlight or hide certain parameters.

## Cost Estimate

Use this report to plan your budget and count the approximate cost of translations. Set the translation and approval rates to see the cost for untranslated and not approved strings in the project.

You can generate a Cost Estimate report based on the following filter parameters:

* Task: Not selected, All tasks, or a specific task.
* Strings Added: Today, Last 7 days, Last 30 days, This month, All time, or Custom range.
* Files: All or specific files.
* Labels (Specific to [projects with labels](/project-settings/labels/)): Not selected, Strings with selected labels, or Strigns without selected labels.
* Language: All languages or a specific target language.

<Aside>
  Final translation cost might differ due to various factors such as added or deleted texts, multiple people translating the same string into the same language (both of them will be counted in the Translation Cost), and others.
</Aside>

### Generating a Report {#generating-cost-estimate}

To generate the Cost Estimate report, follow these steps:

<Steps>
  1. Select the preferred currency and the report unit (words, strings, characters without spaces, or characters with spaces).
  1. Set your [rates](#rates-cost-estimate) for translations and approvals.
  1. Use the available filter parameters to specify the report data you're interested in.
  1. Click **Generate**.
</Steps>

<Image src={costEstimateGenerating} alt="Generating Cost Estimate" />

<Aside>
  Rates are automatically saved after you click *Generate*.
</Aside>

### Rates {#rates-cost-estimate}

You can set the prices for Base rates (full translation, proofread) and configure Net Rate Schemes (percentage of the full translation rate paid for translation using TM suggestions).

#### Base Rates {#base-rates-cost-estimate}

In the Base Rates section, you can set rates for the following types of work:

* **Full translation** &ndash; for each translation made by a person.
  <Aside>If the string has multiple translations made by the same person, only one is counted. If the string has several translations made by different people, each of them is counted.</Aside>
* **Proofread** &ndash; for each approved translation.

#### Net Rate Schemes {#net-rate-schemes-cost-estimate}

In the Net Rate Schemes section, in addition to the base rates, you can set the percentage of the full translation rate to be paid for translations made using TM suggestions of various TM Match types. By default, you can configure the percentage of the full translation rate for the following TM Match types:

- **101 (perfect)** &ndash; for translations made using Perfect match TM suggestions (source strings are identical to TM suggestion by text and context).
- **100** &ndash; for translations made using 100% match TM suggestions (source strings are identical to TM suggestion only by text).

You can also add your own TM match types, specifying the preferred percentage of text similarity and the percentage of the full translation rate to be paid for such a translation.

To add your own TM match types, follow these steps:

<Steps>
  1. Click <Icon name="mdi:cog" class="inline-icon" /> in the Net Rate Schemes section.
  1. Click on the appeared <Icon name="mdi:plus" class="inline-icon" /> button.
  1. Specify the TM match range and the percentage of the full translation rate.
  1. Click <Icon name="mdi:cog" class="inline-icon" /> to save the settings.
</Steps>

<Image src={addTmMatchType} alt="Adding TM Match Type" class="width-lg" />

#### Adding Custom Rates {#custom-rates-cost-estimate}

In addition to base rates that are applied to all languages by default, you can add custom rates for specific languages. To add custom rates, click **Add custom rates**.

To select the language or languages for custom rates, click **Edit Languages** and select the ones you need. You can create as many custom rates as you need.

<Image src={addCustomRates} alt="Adding Custom Rates" />

#### Rate Templates

If you plan to work with multiple rate configurations, save them as templates by clicking **Save as > New rates template**, then specify the template name and click **Save**.

When saving a new template you can choose the template visibility using the following options:

* **Share with all project members** &ndash; makes the template visible to all translators within the project. Regardless of the number of translators or their different rates, they all will have access to the template. It can include both general rates and custom rates for specific languages and translators, along with a net rate scheme. This transparency promotes clarity in pricing, allowing translators to review rates, generate reports on their translations, and calculate cost estimates. The key benefit is that translators understand the net rate scheme and can apply their base rate, even if it's not included in the template.

* **Share with managers within the owner’s projects** &ndash; makes the template global, visible only to managers across all projects of an owner. This option streamlines rate consistency across various projects.

If neither of the options is selected, the template remains visible only to managers within the current project, limiting access to a select group of project members. These options provide flexibility in controlling who can view and use the rate template to accommodate different organizational preferences.

Saved templates allows you to quickly switch between different configurations for report generation.

Click **Templates** to view and manage your saved rate templates.

### Include Pre-translated Strings

Select **Include pre-translated strings** if you want to include pre-translated strings in a Cost Estimate report. By default, this option is selected.

For example, you have an untranslated string `Validate your username` in your project. You generate a Cost Estimate report with the **Include pre-translated strings** option selected. This string will be included in the Cost Estimate. Then you pre-translate this string via TM or MT engine and once again generate a Cost Estimate report with the **Include pre-translated strings** option selected. This time, the pre-translated string `Validate your username` won't be included in the Cost Estimate report.

On the other hand, with the **Include pre-translated strings** option cleared, the string `Validate your username` will be included in the Cost Estimate report both times, when untranslated and when pre-translated via TM or MT engine.

### Calculate Internal Fuzzy Matches

Internal Fuzzy Matches are partial (fuzzy) TM matches found among untranslated strings in your project that can potentially be added to the Translation Memory. For example, if the first string in a file is `Validate your username` and the last one is `Validate your username again`, there is an internal fuzzy match.

To include fuzzy (99% and less) internal matches, as well as perfect (101%) and 100% matches, in your Cost Estimate report and get a more comprehensive prediction of how many strings can be added to the TM if translated in sequence, select **Calculate Internal Fuzzy Matches**. Note that these calculations are approximate because the actual translation order may differ.

If you clear **Calculate Internal Fuzzy Matches**, the Cost Estimate report will only show perfect (101%) and 100% internal matches (repetitions), and will not include any fuzzy matches.

<Aside>
  Internal Fuzzy Matches are counted according to the [Net Rate Schemes](#net-rate-schemes-cost-estimate) configurations.
</Aside>

### Result Analysis {#result-analysis-cost-estimate}

When the Cost Estimate report is generated, it displays the following details:

##### Cost Summary

* **Total** - General cost estimate for all languages (including translation, proofreading, and any TM savings).
* **Subtotals** - Cost estimate for each target language:
  * **Translation** – Cost for strings requiring new or updated translations (no high–percentage match leverage).
  * **Proofreading** – Cost for reviewing translations.
  * **TM Savings** – Savings from existing translations (in TM or within the project).
  * **Weighted Words / Strings / Characters / Characters with Spaces** – Final word count for cost calculations after applying TM/internal match discounts.

##### Categories

Each row in the main table represents a match category or status:

* **Total** – Summarizes all strings, words, and characters, as well as the weighted units after match discounts and percentage of the total.
* **TM Match (total)** – Untranslated strings matching entries in Translation Memory, often split into:
  * **101% (perfect)** – Exact text and context match.
  * **100%** – Exact text match, but context differs.
* **Repetitions (total)** or **Internal Match (total)** – Untranslated strings matching other strings within the project. Displaying depends on whether **Calculate Internal Fuzzy Matches** is enabled. Subcategories (e.g., 101%, 100%, and fuzzy) depend on your Net Rate Schemes.
  <Aside>
    Depending on your project settings, the Cost Estimate report results may vary:
    - If **Auto-substitution** is enabled, some strings initially below 100% may become 100% matches after auto-substitution and be counted under Internal Match.
    - If your project is set to [hide duplicate strings](/project-settings/import/#hide-all-duplicates), the report won’t show any repetitions since they’re not visible for translation.
  </Aside>

  If an untranslated string has both a 101% TM match and a 100% internal match, it counts toward TM match.

* **No Match** – Strings with no TM or internal matches, requiring translation from scratch.
* **Not Approved** – Translated strings that still awaiting approval.
* **Not Translated** – Completely untranslated strings requiring full translation.

##### Columns

* **Strings / Words / Characters / Characters with Spaces** – Basic volume metrics.
  <Aside>
    The selected report unit column is shown in bold, while other unit columns appear in lighter (muted) text.
  </Aside>
* **Weighted Words / Strings / Characters / Characters with Spaces** – Shows the adjusted metric after factoring in repetitions and fuzzy matches, reflecting the actual translation effort.
* **%** – Share of weighted units in each category.

##### Folder/File Breakdown

After the main table, each language subtotal also includes a table showing data for each folder or file, indicating how many strings are **Not Approved**, **Not Translated**, match the **TM**, match **Internal**, or have **No Match**. This helps identify where to focus your translation efforts and budget.

##### Export

To download the Cost Estimate report, click **Export** and select the preferred format (CSV, XLSX, or JSON) for further analysis or record-keeping.

<Image src={costEstimateGenerated} alt="Cost Estimate Generated" />

## Translation Cost

Use this report to calculate the actual translation cost based on the completed job.

You can generate a Translation Cost report based on the following filter parameters:

* Task: Not selected, All Tasks, or specific task.
* Date Range: Today, Yesterday, Last 7 days, Last 30 days, This month, Last month, All time, or Custom range.
* Files: All files (including deleted files and strings) or Selected files (including deleted strings).
* Branches (Specific to [string-based projects](/creating-project/#string-based-project)): All branches or Selected branches.
* Labels (Specific to projects with [labels](/project-settings/labels/)): Not selected, Strings with selected labels, or Strigns without selected labels.
* Language: All or specific target language.
* Member: All or specific users.
* Group by: Member or language.

### Generating a Report {#generating-translation-cost}

To generate the Translation Cost report, follow these steps:

<Steps>
  1. Select the preferred currency and the report unit (words, strings, characters without spaces, or characters with spaces).
  1. Set your [rates](#rates-translation-cost) for translations and approvals.
  1. Use the available filter parameters to specify the report data you're interested in.
  1. Click **Generate**.
</Steps>

<Image src={translationCostGenerating} alt="Generating Translation Cost" />

<Aside>
  Rates are automatically saved after you click **Generate**.
</Aside>

<Aside>
  If the scope of a task changes after contributions have already been made (e.g., if some strings were removed from the task), these contributions will still be included when generating a Translation Cost report for **All Tasks** or a **specific task**.
</Aside>

### Rates {#rates-translation-cost}

You can set the prices for Base rates (full translation, proofread) and configure Net Rate Schemes (percentage of the full translation rate paid for translation using TM suggestions, MT suggestions, and existing translations).

#### Base Rates {#base-rates-translation-cost}

In the Base Rates section, you can set rates for the following types of work:

* **Full translation** &ndash; for each translation made by a person.
  <Aside>If the string has multiple translations made by the same person, only one is counted. If the string has several translations made by different people, each of them is counted.</Aside>
* **Proofread** &ndash; for each approved translation.

#### Net Rate Schemes {#net-rate-schemes-translation-cost}

In the Net Rate Schemes section, in addition to the base rates, you can set the percentage of the full translation rate to be paid for translations made using TM suggestions, MT suggestions, and other translations of various Match types.

By default, you can configure the percentage of the full translation rate for the following match type categories:

**TM Match types:**

- **101 (perfect)** &ndash; for translations made using Perfect match TM suggestions (source strings are identical to TM suggestion by text and context).
- **100** &ndash; for translations made using 100% match TM suggestions (source strings are identical to TM suggestion only by text).

**MT Match types:**

- **100** &ndash; for translations made using 100% match MT suggestions (new suggested translations are identical to MT suggestion).

**AI Match types:**

- **100** &ndash; for translations made using 100% match AI suggestions (new suggested translations are identical to AI suggestion).

**Other translations types:**

- **100** &ndash; for translations made using existing translations (new suggested translations are identical to the existing translations).

If a string has a combination of TM and MT suggestions and existing translations, the new translation is counted at the lowest Net Rate Scheme value. For example, if a string has a 101% (perfect) TM match suggestion (10% of the full translation rate) and a 100% MT match suggestion (5% of the full translation rate), the new translation added to this string will be counted at a 5% of the full translation rate.

You can also add your own TM, MT, and Other translations match types, specifying the preferred percentage of text similarity and the percentage of the full translation rate to be paid for such a translation.

To add your own match types, follow these steps:

<Steps>
  1. Click <Icon name="mdi:cog" class="inline-icon" /> in the Net Rate Schemes section.
  1. Click on the appeared <Icon name="mdi:plus" class="inline-icon" /> button.
  1. Specify the match range and the percentage of the full translation rate.
  1. Click <Icon name="mdi:cog" class="inline-icon" /> to save the settings.
</Steps>

<Image src={addMtMatchType} alt="Adding MT/Other Translation Match Type" />

#### Adding Custom Rates {#custom-rates-translation-cost}

In addition to base rates that are applied to all languages and users by default, you can add custom rates for specific languages and users. To add custom rates, click **Add custom rates**.

To select the languages and users for custom rates, click **Edit Languages** and **Edit Users** and select the ones you need. You can create as many custom rates as you need.

<Image src={addCustomRatesTranslationCost} alt="Adding Custom Rates" />

### Using Additional Translation Cost Options

* **Exclude Approvals for Edited Translations:** select this option to exclude approvals when the same user has translated the string. This helps ensure that your cost reporting is more accurate by avoiding the duplication of approval costs.

* **Pre-Translated Strings Categorization Adjustment:** select this option to have repetitive translations of pre-translated strings categorized under TM or MT match rates, rather than the default Other suggestion match rates. This is useful because post-editing translations from MT engines usually requires more effort than post-editing translations from human translators, leading to a more precise and fair measure of costs related to your translators.

### Result Analysis {#result-analysis-translation-cost}

When the Translation Cost report is generated, it displays the following details:

##### Cost Summary

* **Total** - General translation cost (including TM, MT, and AI savings, weighted words, and pre-translated words).
* **User and Language Totals** - Below the general translation cost, the report shows totals for each user or language, depending on the selected **Group by** filter:
  * **Group by Member** - Shows each translator or proofreader general translation cost (including TM, MT, and AI savings, weighted words, and pre-translated words), along with language subtotals within.
  * **Group by Language** - Shows each target language general translation cost (including TM, MT, and AI savings, weighted words, and pre-translated words), along with translator or proofreader subtotals within.
* **Subtotals** - Subtotal translation cost for each target language or user:
  * **Savings** - The amount saved with leveraged matches from TM, MT, or AI.
  * **Weighted Words / Strings / Characters / Characters with Spaces** – Shows the adjusted metric after applying repetitions and fuzzy matches, reflecting the actual translation effort.
  * **Pre-translated Words / Strings / Characters / Characters with Spaces** - Shows how many units were pre-translated.

Within each user (or language) section, you’ll see a further breakdown of work types and match types in the tables:

##### Translation & Post-Editing

Each row in the Translation & Post-Editing section represents a match category or total:

* **No Match** – No leverage from TM, MT, or AI (full rate).
* **TM Match** – Uses Translation Memory (with possible subcategories like **101% (perfect)** or **100%**).
* **MT Match** – Uses Machine Translation (e.g., **100%**).
* **AI Match** – Uses AI-based suggestions (e.g., **100%**).
* **Other translations Match** – Leverage from existing translations added by other users.
* **Total** – Summarizes all translated units under that user/language.

##### Columns

* **Strings / Words / Characters / Characters with Spaces** – Number of units handled at each match type.
* **Rate per unit** – The price assigned per match type (based on your configured [Net Rate Schemes](#net-rate-schemes-translation-cost) and base rates).
* **Price** – Total cost for the units × rate in that match category.

##### Proofreading

* **Words / Strings / Characters / Characters with Spaces** – Number of units that were proofread and approved.
* **Rate per unit** – Proofreading rate.
* **Price** – Total cost for proofread units (units × rate).

##### Export

To download the Translation Cost report, click **Export** and select the preferred format (CSV, XLSX, or JSON) for further analysis or record-keeping.

<Image src={translationCostGenerated} alt="Translation Cost Generated" />

## Pre-translation Accuracy

Use this report to evaluate the translation quality of pre-translation methods (via AI, MT, and TM) used in your project by analyzing the post-editing effort required for pre-translated strings before approval. It compares the initial pre-translated strings with the final approved translations after post-editing, categorizing data based on the edit distance and pre-translation method. This report allows you optimize your translation workflows and improve overall content quality by identifying the best-performing pre-translation methods.

The edit distance metric is calculated at the character level, while the report mode selection (Strings, Words, Chars) only affects how results are displayed:
- Strings – The entire string is placed in a category if its total edit distance falls within the range.
- Words – All words in the string are placed in the category.
- Chars – All characters in the string are placed in the category.

### Report Scope

* Includes only approved strings with at least one pre-translation.
* If multiple pre-translations exist for a string, each is included with its edit distance.
* Only the top translation is used for comparison if multiple approvals exist.

### Use Case and Best Practices

**Typical Use Case:**

<Steps>
  1. Launch Pre-translation &ndash; use different methods (via AI, MT, and TM) for a portion of your content. Alternatively, you can use one method (e.g., AI) and compare various prompts with different settings.
  2. Invite a Proofreader &ndash; have the pre-translated content reviewed and approved by a proofreader.
  3. Generate Report &ndash; use the Pre-translation Accuracy report to evaluate which pre-translation method performed best by requiring the least amount of post-editing.
  4. Optimize Workflow &ndash; use the most effective pre-translation method for all your content.
</Steps>

**Best Practices:**

* **Regular Reviews** &ndash; regularly generate and review the report to stay informed about the performance of your pre-translation methods.
* **Adjust Methods** &ndash; use the insights from the report to adjust your pre-translation methods. For example, if AI pre-translations require minimal edits, consider increasing their use.

### Generating a Report {#generating-pre-translation-accuracy}

You can generate a Pre-translation Accuracy report based on the following filters:

* **Task** &ndash; Not selected, All Tasks, or a specific task.
* **Language** &ndash; All, or specific language.
* **Strings added (Date range of when the strings were approved)** &ndash; Today, Yesterday, Last 7 days, Last 30 days, This month, Last month, All time, or Custom range.

Additionally, using the report's **Settings**, you can adjust how post-editing information is displayed on the graphs:

* **Total** &ndash; aggregates all post-editing data without breaking it into subcategories.
* **Split into Categories by Edit Distance %** &ndash; offers a detailed view by categorizing units based on the extent of editing required.

To generate the Pre-translation Accuracy report, follow these steps:

<Steps>
  1. Select the preferred report unit (words, strings, characters with or without spaces).
  2. Select the preferred way to group the histogram data (Day or Month).
     * When grouped by Day, the stacked histogram will have more bars, giving a more granular, day-by-day view.
     * When grouped by Month, the data is displayed in fewer, broader monthly segments.
  3. *(Optional)* Select the task if you want to generate a report based on work done within all or specific tasks. Alternatively, leave it as **Not selected** to generate a report based on a wider content scope.
  4. Select the preferred language.
  5. Select the time range.
  6. Click **Settings** and select one of the available options to configure how you want the post-editing information to be displayed.
  7. Click **Generate**.
</Steps>

### Result Analysis {#result-analysis-pre-translation-accuracy}

When the report is generated, you will see the information grouped into pre-translation methods (via AI, MT, and TM):

* Pre-translation via AI:
  * Total approved words, pre-translated by AI
  * Separate graphs for each prompt
* Pre-translation via MT:
  * Total approved words, pre-translated by MT
  * Separate graphs for each MT engine
* Pre-translation via TM:
  * Total approved words, pre-translated by TM

In each section, the data is displayed as histograms and pie charts:

* **Stacked Histogram** &ndash; visualizes the distribution of units approved with or without edits. It categorizes units based on the extent of post-editing, such as:
  * Approved with no post-edit
  * Post-edited with varying degrees of edit distance

* **Pie Chart** &ndash; displays the proportion of units approved with no post-edits compared to those that were post-edited. This provides a clear view of the percentage breakdown of pre-translated units.

To download the Pre-translation Accuracy report, click **Export** and select the preferred export format (CSV, XLSX, or JSON).

<Image src={preTranslationAccuracyGenerated} alt="Pre-translation Accuracy Generated" />

## Translator Accuracy

Use this report to evaluate the translation quality of individual translators in your project by analyzing the post-editing efforts required before their translations are approved. It compares each translator’s initial translation with the final approved version, categorizing the data based on edit distance. This allows you to identify top-performing translators and those who may need additional guidance or training.

### Report Scope

* Includes only approved strings with at least one translation submitted by a human translator.
* If multiple translations exist for a string, each is included with its edit distance.
* Only the top translation is used for comparison if multiple approvals exist.

### Use Case and Best Practices

**Typical Use Case:**

<Steps>
  1. Collect Translations &ndash; have your translators work on the project’s content.
  2. Proofread and Approve &ndash; invite your proofreaders to review and approve the translated strings.
  3. Generate Report &ndash; use the Translator Accuracy report to evaluate each translator’s work, based on how much post-editing was required.
  4. Optimize Translation Team &ndash; identify top-performing translators (those with minimal post-edits) and provide targeted feedback or training where needed.
</Steps>

**Best Practices:**

* **Regular Reviews** &ndash; generate and review this report periodically to keep track of translator performance and spot trends in post-editing needs.
* **Targeted Feedback** &ndash; use the insights to guide training or feedback sessions, focusing on specific areas where translators may need improvement.

### Generating a Report {#generating-translator-accuracy}

You can generate a Translator Accuracy report based on the following filters:

* **Users** &ndash; All, or selected users.
* **Language** &ndash; All, or specific language.
* **Strings approved** &ndash; Today, Yesterday, Last 7 days, Last 30 days, This month, Last month, All time, or Custom range.

Additionally, using the report's **Settings**, you can adjust how post-editing information is displayed:

* **Total** &ndash; aggregates all post-editing data without breaking it into subcategories.
* **Split into Categories by Edit Distance %** &ndash; provides a more granular view by grouping translations based on the extent of editing required.

To generate the Translator Accuracy report, follow these steps:

<Steps>
  1. Select the preferred report unit (words, strings, characters with or without spaces).
  2. *(Optional)* Select one or more users if you want to generate the report for specific translators only. Otherwise, choose **All** to include everyone.
  3. Select the preferred language or choose **All** if you want to include every target language.
  4. Select the time range.
  5. Click **Settings** and select one of the available options to configure how you want the post-editing information to be displayed.
  6. Click **Generate**.
</Steps>

### Result Analysis {#result-analysis-translator-accuracy}

When the report is generated, you will see the information grouped by language, and each translator is listed with their individual statistics:

In each section, the data is displayed as pie charts:

* **Pie Chart** &ndash; displays the proportion of units approved with or without edits. It categorizes units based on the extent of post-editing, such as:
  * No post-edit &ndash; displays that no further proofreader edits were made to the translator’s initial translation.
  * Post-edited with varying degrees of edit distance &ndash; displays one or more slices if you chose **Split into Categories by Edit Distance %**, each slice representing different ranges of edits applied to the translator’s work.
If you selected **Total**, you’ll see just two slices: **No post-edit** and **Post-edited**.

To download the Translator Accuracy report, click **Export** and select the preferred export format (CSV, XLSX, or JSON).

<Image src={translatorAccuracyGenerated} alt="Translator Accuracy Generated" />

## Contribution Raw Data Report

In addition to the Translation Cost report, which is based on the Contribution Raw Data and grouped by languages, you can retrieve this detailed contribution raw data using the [Generate Report](/developer/api/v2/#operation/api.projects.reports.post) (Contribution Raw Data schema) or via the [Raw Report Data](https://store.crowdin.com/raw-report) app available on the Crowdin Store. This allows you to generate your own custom report according to your specific requirements.

The Contribution Raw Data report provides various columns depending on the selected mode (translations, approvals, or votes). Each column offers specific insights, for example `source string text hash`, which is useful for identifying changes in source strings despite having the same `stringId`. It's important to note that multiple records can exist for the same `stringId` if the source hash or plural form varies.

For repeated translations by the same user on the same source string, into the same target language, the same plural form, and if the source text has not changed, only the `translationId`, `targetUnits`, and `updatedAt` columns will update in the report statistics. Deleted translations are also included in the count. Understanding these columns can help you better interpret the raw data and optimize your localization process.

View the available report columns and their mode applicability (i.e., translations, approvals, and votes) in the following table:

<Include file="contribution-raw-data-report-columns.mdx" />

## Top Members

The Top Members report allows you to see who contributed the most to your project's translation.

Default parameters:
- *Text unit*: words
- *Time period*: Last 30 days
- *Sorted by*: translated text units. A member who translated the most is placed at the top of the list.
- *Languages*: all languages
- *Contributors*: all

The **YOU** label appears next to your own username in the report table, making it easier to identify your personal contribution.

Re-sort the members by clicking on the needed parameter. For example, if you want to analyze members by their proofreading activity, click on the *Approved* parameter to redo sorting.

### Generating a Custom List of Top Members

To generate a custom list of top members, follow these steps:

<Steps>
  1. Select the preferred report unit (words, strings, characters with or without spaces).
  1. Select the time period for which you want to see the activity of contributors.
  1. To make a list of contributors for a specific language, select the language you need from the drop-down menu above the list. Alternatively, select **All languages**.
  1. Click **Generate**.
</Steps>

To find a specific member, use the search field. To open the member’s profile page, double-click on the name.

The Top Members list includes the following columns:

* *Rank* &ndash; contributor’s position in the list based on the currently selected sorting criteria (e.g., *Translated*, *Approved*, etc.).
* *Name* &ndash; contributor's first name, last name and username.
* *Languages* &ndash; project languages.
* *Translated* &ndash; the number of translated source content units.
* *Target Words* &ndash; the number of translated content units in a target language.
<br/> This parameter is not available for the *Strings* content unit because the number of source and translated strings is always the same.
* *Approved* &ndash; the number of approved content units.
* *Voted* &ndash; the number of votes a contributor made.
* *"+" votes received* &ndash; the number of upvotes a contributor received for translations.
* *"-" votes received* &ndash; the number of downvotes a contributor received for translations.
* *Winning* &ndash; the number of approvals a contributor received for translations.
* *Joined* &ndash; the date a member joined a project.

To customize the visibility of columns in the report, click <Icon name="material-symbols:table-chart" class="inline-icon" /> at the upper-right side of the table and select the preferred ones.

To download the Top Members report, click **Export** and select the preferred export format (CSV, XLSX, or JSON).

<Image src={topMembers} alt="Generating a list of Top Members" />

## Archive

The Archive section allows you to access the records of previously generated Cost estimate and Translation cost reports, providing a convenient way to review historical data.

This section also eliminates the need to wait for a report generation to complete. You can initiate a report generation and return to it later at your convenience. Within the Archive, you can review the report summary and, if necessary, download it in various supported file formats.

Each project has its own independent archive section with previously generated reports available only to project members with manager permissions (or higher).

Reports generated by translators based on their contributions are not added to the archives.

### Viewing Previously Generated Reports

To view the summary of the previously generated reports (i.e., archive records), follow these steps:

<Steps>
  1. Open your project and go to **Reports > Archive**.
  1. Click on the name of the needed archive record.
  1. Once you open the archive report record, you can view all the needed data.
</Steps>

<Image src={archiveViewing} alt="Viewing Previously Generated Reports" />

### Exporting Previously Generated Reports

To export the previously generated reports, follow these steps:

<Steps>
  1. Open your project and go to **Reports > Archive**.
  1. Click <Icon name="mdi:dots-horizontal" class="inline-icon" /> on the needed report in the list.
  1. Click on the preferred file format to export.
</Steps>

### Deleting Previously Generated Reports

To delete the previously generated reports, follow these steps:

<Steps>
  1. Open your project and go to **Reports > Archive**.
  1. Click <Icon name="mdi:dots-horizontal" class="inline-icon" /> on the needed report in the list.
  1. Click **Delete**.
</Steps>

## See Also

<LinkCard
  title="Contributor Reports"
  description="Estimate and count the price of your contribution to the project."
  href="/contributor-reports/"
/>
